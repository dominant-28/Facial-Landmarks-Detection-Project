{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToPILImage\n",
    "import torchvision.datasets as dsets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataloader\n",
    "class BSD100Dataset(Dataset):\n",
    "    def __init__(self, rootdir, transform=None):\n",
    "\n",
    "        self.root_dir = rootdir\n",
    "        self.transform = transform\n",
    "        self.imnames = [f for f in os.listdir(rootdir) if f.endswith('.jpg') or f.endswith('.png')]  #list the file which is ending with the .jpg or .png \n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imnames)   #for getting the length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        imname = os.path.join(self.root_dir, self.imnames[2*idx]) #seperating the training images and label images\n",
    "        labelspath=os.path.join(self.root_dir, self.imnames[2*idx+1])\n",
    "        image = Image.open(imname)\n",
    "        labels=Image.open(labelspath)\n",
    "        sample = {'image': image,'label':labels}\n",
    "        #applying transformations\n",
    "        if self.transform:\n",
    "            sample['image'] = self.transform(sample['image'])\n",
    "            sample['label'] = self.transform(sample['label'])\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=BSD100Dataset(rootdir=r'C:\\Users\\soham\\OneDrive\\Documents\\ALL TASK OF FACIAL LANDMARK PROJECT\\task_5_customdataloader\\BSD100\\image_SRF_2', transform=transform)\n",
    "#creating the batches\n",
    "dataloader=DataLoader(dataset,batch_size=4,shuffle=True,num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#showing the output\n",
    "image=dataset[0]['image']\n",
    "image2=dataset[10]['image']\n",
    "image3=dataset[50]['image']\n",
    "image = np.transpose(image, (1, 2, 0))\n",
    "image2= np.transpose(image2, (1, 2, 0))\n",
    "image3= np.transpose(image3, (1, 2, 0))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(image)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(image2)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(image3)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
