{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inporting all dependencies\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading CIFAR10 dataset and creating the batches from it\n",
    "traindata=torchvision.datasets.CIFAR10(root=\"data\",train=True,download=True,transform=transforms.ToTensor())\n",
    "testdata=torchvision.datasets.CIFAR10(root=\"data\",train=False,download=True,transform=transforms.ToTensor())\n",
    "trainloader=torch.utils.data.DataLoader(traindata,batch_size=100,shuffle=True)\n",
    "testloader=torch.utils.data.DataLoader(testdata,batch_size=100,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Network for the model\n",
    "class cnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(cnn,self).__init__()\n",
    "        self.conv1=nn.Conv2d(3,16,3,1,padding=1)\n",
    "        self.conv2=nn.Conv2d(16,32,3,1,padding=1)\n",
    "        self.conv3=nn.Conv2d(32,64,3,1,padding=1)\n",
    "        self.conv4=nn.Conv2d(64,128,3,1,padding=1)\n",
    "        self.conv5=nn.Conv2d(128,256,3,1,padding=1)\n",
    "        self.b1=nn.BatchNorm2d(16)\n",
    "        self.b2=nn.BatchNorm2d(64)  #batch normalization\n",
    "        self.b3=nn.BatchNorm2d(256)\n",
    "        self.pool=nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "\n",
    "        self.dropout=nn.Dropout(0.1)\n",
    "        self.fc1=nn.Linear(256,128)\n",
    "        self.fc2=nn.Linear(128,64)  #fully connected layer\n",
    "        self.out=nn.Linear(64,10)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.pool(f.relu(self.b1(self.conv1(x))))\n",
    "        x=self.pool(f.relu(self.conv2(x)))\n",
    "        x=self.pool(f.relu(self.b2(self.conv3(x))))\n",
    "        x=self.pool(f.relu(self.conv4(x)))\n",
    "        x=self.pool(f.relu(self.b3(self.conv5(x))))\n",
    "        x=x.view(-1,256)         #falttening\n",
    "        x = self.dropout(x)\n",
    "        x=self.dropout(f.relu(self.fc1(x)))\n",
    "        x=self.dropout(f.relu(self.fc2(x)))\n",
    "        x=self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model=cnn().to(device)\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=optim.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training loop\n",
    "for epoch in range(50):\n",
    "  model.train()\n",
    "  costs=[]\n",
    "  acuracies=[]\n",
    "  correct=0\n",
    "  total=0\n",
    "  #iterating over batches\n",
    "  for batch,(data,target) in enumerate(trainloader):\n",
    "    data,target=data.to(device),target.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    output=model(data)\n",
    "    pred=output.argmax(dim=1,keepdim=True)\n",
    "    correct+=pred.eq(target.view_as(pred)).sum().item()\n",
    "    total+=target.size(0)\n",
    "    acuracies.append((correct/total)*100)\n",
    "    loss=criterion(output,target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    costs.append(loss.cpu().detach().numpy())\n",
    "  if(epoch%10==0):\n",
    "    print(f\"the loss after the {epoch} epoch is:{loss},accuracy:{(correct/total)*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#ploting the cost vs iterations\n",
    "plt.plot(costs)\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"cost\")\n",
    "plt.title(\"cost vs iterations\")\n",
    "plt.show()\n",
    "\n",
    "#ploting the acuracy vs iterations\n",
    "plt.plot(acuracies)\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"acuracy\")\n",
    "plt.title(\"acuracy vs iterations\")\n",
    "plt.show()\n",
    "#function for evaluating model on the testset\n",
    "def test():\n",
    "  model.eval()\n",
    "  correct=0\n",
    "  with torch.no_grad():\n",
    "    for data,target in testloader:\n",
    "      data,target=data.to(device),target.to(device)\n",
    "      output=model(data)\n",
    "      pred=output.argmax(dim=1,keepdim=True)\n",
    "      correct+=pred.eq(target.view_as(pred)).sum().item()\n",
    "  print(f\"accuracy on testset:{(correct/len(testloader.dataset))*100}\")\n",
    "\n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
